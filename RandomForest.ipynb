{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637' \n",
    "\n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "                \n",
    "# download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "# download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean the comment text  \n",
    "The text_clean is a pipeline of work that clean the comments text.\n",
    "* split the entire comment string into words\n",
    "* remove token \"NEWLINE_TOKEN\"\n",
    "* remove token \"TAB_TOKEN\"\n",
    "* convert all words to lowercase\n",
    "* filter out punctuation\n",
    "* filter out stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "\n",
    "def text_clean(text):\n",
    "    tokens = word_tokenize(text)\n",
    "#     tokens = re.split(r'\\W+', text)\n",
    "    tokens = [w.replace(\"NEWLINE_TOKEN\", \" \") for w in tokens]\n",
    "    tokens = [w.replace(\"TAB_TOKEN\", \" \") for w in tokens]\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "#     stop_words_list = set(stopwords.words('english'))\n",
    "#     tokens = [w for w in tokens if w not in stop_words_list]\n",
    "    filted_text = ' '.join(tokens)\n",
    "    return filted_text\n",
    "comments['comment'] = comments['comment'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "801279                           iraq is not good usa is bad\n",
       "2702703    off you little asshole if you want to talk to ...\n",
       "4632658           i have a dick its bigger than yours hahaha\n",
       "6545332    renault sad little bpy for driving a renault c...\n",
       "6545351    renault sad little bo for driving a renault cl...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.query('attack')['comment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N gram Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_comments = comments.query(\"split== 'train'\")\n",
    "test_comments = comments.query(\"split== 'test'\")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', RandomForestClassifier(\n",
    "                                    n_estimators=500,\n",
    "#                                    max_features='sqrt', \n",
    "#                                    min_samples_leaf=15, \n",
    "#                                    min_samples_split=5, \n",
    "#                                    max_depth= 50, \n",
    "#                                    class_weight='balanced_subsample',\n",
    "                                   random_state=0)\n",
    "                                   ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under the Receiver Operating Characteristic Curve\n",
    "The high the score the better the classifier is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.946\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test_comments['attack'], clf.predict_proba(test_comments['comment'])[:,1])\n",
    "print('Test ROC AUC: %.3f' %auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Accuracy and Testing Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training subset: 0.999\n",
      "Accuracy on the testing subset: 0.935\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = clf.score(train_comments['comment'], train_comments['attack'])\n",
    "print('Accuracy on the training subset: %.3f' %train_accuracy)\n",
    "test_accuracy = clf.score(test_comments['comment'], test_comments['attack'])\n",
    "print('Accuracy on the testing subset: %.3f' %test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consufion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_comments['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.94      0.99      0.96     20422\n",
      "       True       0.91      0.50      0.64      2756\n",
      "\n",
      "avg / total       0.93      0.93      0.93     23178\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"d7367373-af69-415c-9465-b62736b1f7f9\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"d7367373-af69-415c-9465-b62736b1f7f9\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Yay!!!!!!!!!!!!!!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Yay!!!!!!!!!!!!!!\"\n",
    "\n",
    "from sklearn import metrics\n",
    "# print(test_comments['attack'])\n",
    "# print(clf.predict_proba(test_comments['comment']))\n",
    "print(metrics.classification_report(test_comments['attack'], predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000)),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', RandomForestClassifier(n_jobs=-1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': [100, 200, 300],\n",
      " 'clf__min_samples_leaf': [20, 50, 80],\n",
      " 'clf__n_estimators': [300, 500, 700]}\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "           \"clf__n_estimators\" : [300, 500, 700],\n",
    "           \"clf__max_depth\" : [100, 200, 300],\n",
    "           \"clf__min_samples_leaf\" : [20, 50, 80]}\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=10000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        stri..._jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__n_estimators': [300, 500, 700], 'clf__max_depth': [100, 200, 300], 'clf__min_samples_leaf': [20, 50, 80]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs_clf = GridSearchCV(estimator=text_clf, param_grid=param_grid, n_jobs=-1)\n",
    "gs_clf.fit(train_comments['comment'], train_comments['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cb99e08a381d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gs_clf' is not defined"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "## Text cleaning methods that I applyed\n",
    "* split the comment string into words\n",
    "* remove token \"NEWLINE_TOKEN\"\n",
    "* remove token \"TAB_TOKEN\"\n",
    "* convert all words to lowercase\n",
    "* filter out punctuation\n",
    "* filter out stop words \n",
    "\n",
    "## Feature Extraction\n",
    "* N gram feature\n",
    "     * Character level\n",
    "     * Word level\n",
    "* Embedding derived feature\n",
    "    * Word2vec\n",
    "    * Dor2vec\n",
    "* Syntactic feature\n",
    "\n",
    "I applyied N-gram feature to all three models\n",
    "\n",
    "## Models\n",
    "* KNN \n",
    "    \n",
    "      precision    recall  f1-score   support\n",
    "      False       0.90      0.97      0.94     20422\n",
    "      True       0.53      0.24      0.33      2756\n",
    "      avg / total       0.86      0.88      0.86     23178\n",
    "* Multinomial Naive Bayes\n",
    "    \n",
    "       precision    recall  f1-score   support\n",
    "       False       0.94      0.99      0.96     20422\n",
    "       True       0.84      0.55      0.67      2756\n",
    "       avg / total   0.93      0.93      0.93     23178\n",
    "\n",
    "* Random Forest\n",
    "        \n",
    "      precision    recall  f1-score   support\n",
    "      False       0.95      0.98      0.97     20422\n",
    "       True       0.83      0.61      0.70      2756\n",
    "       avg / total       0.94      0.94      0.93     23178\n",
    "       \n",
    "Best model: Random Forest\n",
    "\n",
    "## Hyper-parameter Tuning\n",
    "\n",
    "### Multinomial Naive Bayes\n",
    "    \n",
    "    parameters = {'vect__ngram_range':[(1,2), (1,3)],\n",
    "              'tfidf__use_idf':(True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "            }\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "\n",
    "    param_grid = { \n",
    "           \"clf__n_estimators\" : [300, 500, 700],\n",
    "           \"clf__max_depth\" : [1, 15, 30],\n",
    "           \"clf__min_samples_leaf\" : [1, 6, 12]}\n",
    "           \n",
    "Somehow, I did not successfully calculate the result due to lack of GPU running time on Google.\n",
    "\n",
    "## Metrics\n",
    "* I learn that Random forest has high F1 score comparing to that of Naive Bayes.\n",
    "* Random forest did a better job on find comments that contains personal attack.\n",
    "* I did not get to compute the result of cross-validation.\n",
    "\n",
    "## Result\n",
    "* The Random Forest model gives the best result, however it has lower auc_roc score than the logistic regression model.\n",
    "* Random Forest gives almost the same accuracy as Logistic Regression does on testing.\n",
    "\n",
    "## Interesting thing about this project\n",
    "* learned about different between parametric model and non-parametric model\n",
    "* Introduction to sklearn which is a very powerful tool.\n",
    "\n",
    "## hardest thing\n",
    "* Tunning Hyper-parater is the hartest part, because it requires you to understand your dataset and model before choosing the range of the parameters, otherwise you will have to wait for a long time for the result of best parameters.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
